{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19687/804492180.py:8: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2416.)\n",
      "  Q, _ = torch.qr(torch.randn(dim, dim))\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4321)\n",
    "dim=20\n",
    "c = torch.randn((dim, 1), requires_grad=False)\n",
    "d = torch.randn((dim, 1), requires_grad=False)\n",
    "A = torch.randn((dim, dim), requires_grad=False)\n",
    "\n",
    "eigenvalues = torch.empty(dim).uniform_(0.1, 1)\n",
    "Q, _ = torch.qr(torch.randn(dim, dim))\n",
    "D = torch.diag(eigenvalues)\n",
    "H = Q @ D @ Q.T\n",
    "\n",
    "torch.save(A, 'data/A.pt')\n",
    "torch.save(H, 'data/H.pt')\n",
    "torch.save(c, 'data/c.pt')\n",
    "torch.save(d, 'data/d.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Hyper-Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classes: 7 and 8\n",
      "Train: torch.Size([1401, 784]), torch.Size([1401, 2])\n",
      "Validation: torch.Size([300, 784]), torch.Size([300, 2])\n",
      "Test: torch.Size([301, 784]), torch.Size([301, 2])\n",
      "Number of corrupted labels: 711\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "\n",
    "p = 0.5  # corruption probability\n",
    "\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Randomly select two different classes\n",
    "classes = list(range(10))\n",
    "class1 = random.choice(classes)\n",
    "class2 = random.choice([c for c in classes if c != class1])\n",
    "\n",
    "# Function to filter data for the selected classes\n",
    "def filter_mnist_by_class(data, class1, class2):\n",
    "    indices = (data.targets == class1) | (data.targets == class2)\n",
    "    filtered_data = data.data[indices]\n",
    "    filtered_targets = data.targets[indices]\n",
    "    # Convert labels to binary {-1, 1}\n",
    "    filtered_targets = torch.where(filtered_targets == class1, torch.tensor(0), torch.tensor(1))\n",
    "    return filtered_data, filtered_targets\n",
    "\n",
    "# Filter the data\n",
    "data, targets = filter_mnist_by_class(mnist_data, class1, class2)\n",
    "\n",
    "# Flatten the images and split into train, validation, and test sets\n",
    "n_samples = data.shape[0]\n",
    "n_train = int(0.7 * n_samples)\n",
    "n_val = int(0.15 * n_samples)\n",
    "n_test = n_samples - n_train - n_val\n",
    "\n",
    "# Shuffle the data\n",
    "indices = torch.randperm(n_samples)\n",
    "data = data[indices].float().view(n_samples, -1) / 255.0  # Normalize and flatten\n",
    "targets = targets[indices]\n",
    "\n",
    "# Split the data\n",
    "A_tr, B_tr_true = data[:n_train], targets[:n_train]\n",
    "A_val, B_val = data[n_train:n_train+n_val], targets[n_train:n_train+n_val]\n",
    "A_test, B_test = data[n_train+n_val:], targets[n_train+n_val:]\n",
    "\n",
    "# Randomly corrupt some of the training samples\n",
    "corruption_mask = np.random.rand(n_train) < p\n",
    "B_tr = B_tr_true.clone()  # Clone to avoid modifying the original labels\n",
    "B_tr[corruption_mask] = 1 -  B_tr_true[corruption_mask]  # Flip the labels where corruption_mask is True\n",
    "\n",
    "B_tr = torch.nn.functional.one_hot(B_tr, num_classes=2)\n",
    "B_val = torch.nn.functional.one_hot(B_val, num_classes=2)\n",
    "B_test = torch.nn.functional.one_hot(B_test, num_classes=2)\n",
    "\n",
    "# Output shapes and corruption details\n",
    "print(f'Selected classes: {class1} and {class2}')\n",
    "print(f'Train: {A_tr.shape}, {B_tr.shape}')\n",
    "print(f'Validation: {A_val.shape}, {B_val.shape}')\n",
    "print(f'Test: {A_test.shape}, {B_test.shape}')\n",
    "print(f'Number of corrupted labels: {corruption_mask.sum()}')\n",
    "\n",
    "\n",
    "torch.save(A_tr, 'data/A_tr.pt'); \n",
    "torch.save(A_val, 'data/A_val.pt');\n",
    "torch.save(A_test, 'data/A_test.pt');\n",
    "torch.save(B_tr, 'data/B_tr.pt');\n",
    "torch.save(B_val, 'data/B_val.pt');\n",
    "torch.save(B_test, 'data/B_test.pt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: torch.Size([7000, 784]), torch.Size([7000, 10])\n",
      "Validation: torch.Size([1500, 784]), torch.Size([1500, 10])\n",
      "Test: torch.Size([1500, 784]), torch.Size([1500, 10])\n",
      "Number of corrupted labels: 3414\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "\n",
    "# p = 0.4  # corruption probability\n",
    "\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "data, targets = mnist_data.data, mnist_data.targets\n",
    "\n",
    "# Flatten the images and split into train, validation, and test sets\n",
    "n_samples = data.shape[0]\n",
    "n_train = int(0.7 * n_samples)\n",
    "n_val = int(0.15 * n_samples)\n",
    "n_test = n_samples - n_train - n_val\n",
    "\n",
    "# Shuffle the data\n",
    "indices = torch.randperm(n_samples)\n",
    "data = data[indices].float().view(n_samples, -1) / 255.0  # Normalize and flatten\n",
    "targets = targets[indices]\n",
    "\n",
    "# Split the data\n",
    "A_tr, B_tr_true = data[:n_train], targets[:n_train]\n",
    "A_val, B_val = data[n_train:n_train+n_val], targets[n_train:n_train+n_val]\n",
    "A_test, B_test = data[n_train+n_val:], targets[n_train+n_val:]\n",
    "\n",
    "# # Randomly corrupt some of the training samples\n",
    "corruption_mask = torch.rand(n_train) < p\n",
    "B_tr = B_tr_true.clone()  # Clone to avoid modifying the original labels\n",
    "\n",
    "# Generate random labels for the corrupted samples\n",
    "random_labels = torch.randint(1, 10, (n_train,))  # Random integers from 1 to 9\n",
    "\n",
    "# Apply the corruption, ensuring new labels are different from the original\n",
    "B_tr[corruption_mask] = (B_tr_true[corruption_mask] + random_labels[corruption_mask]) % 10\n",
    "\n",
    "B_tr = torch.nn.functional.one_hot(B_tr, num_classes=10)\n",
    "B_val = torch.nn.functional.one_hot(B_val, num_classes=10)\n",
    "B_test = torch.nn.functional.one_hot(B_test, num_classes=10)\n",
    "\n",
    "\n",
    "# Output shapes and corruption details\n",
    "print(f'Train: {A_tr.shape}, {B_tr.shape}')\n",
    "print(f'Validation: {A_val.shape}, {B_val.shape}')\n",
    "print(f'Test: {A_test.shape}, {B_test.shape}')\n",
    "print(f'Number of corrupted labels: {corruption_mask.sum()}')\n",
    "\n",
    "\n",
    "torch.save(A_tr, 'data/A_tr.pt'); \n",
    "torch.save(A_val, 'data/A_val.pt');\n",
    "torch.save(A_test, 'data/A_test.pt');\n",
    "torch.save(B_tr, 'data/B_tr.pt');\n",
    "torch.save(B_val, 'data/B_val.pt');\n",
    "torch.save(B_test, 'data/B_test.pt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (7000, 31), torch.Size([7000, 10])\n",
      "Validation: (1500, 31), torch.Size([1500, 10])\n",
      "Test: (1500, 31), torch.Size([1500, 10])\n",
      "Number of corrupted labels: 3414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(A_tr)\n",
    "index = np.where(np.cumsum(pca.explained_variance_ratio_) >= 0.75)[0][0]\n",
    "\n",
    "pca = PCA(n_components=index)\n",
    "pca.fit(A_tr)\n",
    "A_tr2 = pca.transform(A_tr)\n",
    "A_val2 = pca.transform(A_val)\n",
    "A_test2 = pca.transform(A_test)\n",
    "\n",
    "# Output shapes and corruption details\n",
    "print(f'Train: {A_tr2.shape}, {B_tr.shape}')\n",
    "print(f'Validation: {A_val2.shape}, {B_val.shape}')\n",
    "print(f'Test: {A_test2.shape}, {B_test.shape}')\n",
    "print(f'Number of corrupted labels: {corruption_mask.sum()}')\n",
    "\n",
    "torch.save(torch.tensor(A_tr2), 'data/A_tr.pt');\n",
    "torch.save(torch.tensor(A_val2), 'data/A_val.pt');\n",
    "torch.save(torch.tensor(A_test2), 'data/A_test.pt');\n",
    "torch.save(B_tr, 'data/B_tr.pt');\n",
    "torch.save(B_val, 'data/B_val.pt');\n",
    "torch.save(B_test, 'data/B_test.pt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7000, 784]),\n",
       " tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_tr.shape, B_tr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
